{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726f3d23-5428-407a-8a37-cb24fe54ddd4",
   "metadata": {},
   "source": [
    "For this week’s assignment, you are required to investigate the accuracy-computation time tradeoffs of the different optimization algorithms (solvers) that are available for fitting linear regression models in Scikit-Learn. Using the code shared via the Python notebook (part of this week’s uploads archive) where the use of logistic regression was demonstrated, complete the following operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037ab2c-256a-48e5-a4fe-978affd21191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17f4a3c6-98dd-4a6f-815a-884970c22113",
   "metadata": {},
   "source": [
    "1.Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a311f7fe-39ae-481b-82e2-a6cd5bb89c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c31629a8-e2c1-484e-b209-b7cb7d59f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas version: 2.2.2\n",
      "Matplotlib version: 3.8.4\n",
      "Numpy version: 1.26.4\n",
      "SciKitLearn version: 1.4.2\n",
      "My working directory:\n",
      "C:\\Users\\rathn\n",
      "My new working directory:\n",
      "C:\\Users\\rathn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.81       970\n",
      "         1.0       0.66      0.52      0.58       530\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.71      0.68      0.69      1500\n",
      "weighted avg       0.73      0.73      0.72      1500\n",
      "\n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.80       970\n",
      "         1.0       0.65      0.52      0.58       530\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.71      0.68      0.69      1500\n",
      "weighted avg       0.72      0.73      0.72      1500\n",
      "\n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "Logistic_SL1_C_auto    0.7307   0.714 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "Logistic_SL1_C_auto    0.7307   0.714 \n",
      "RandomForest_noCV      0.9993   0.684 \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "Logistic_SL1_C_auto    0.7307   0.714 \n",
      "RandomForest_noCV      0.9993   0.684 \n",
      "RandomForest_CV        0.9993   0.7   \n",
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "Logistic_SL1_C_auto    0.7307   0.714 \n",
      "RandomForest_noCV      0.9993   0.684 \n",
      "RandomForest_CV        0.9993   0.7   \n",
      "RandomForest_CV2       0.796    0.716 \n"
     ]
    }
   ],
   "source": [
    "%run Machine_Learning_Review_Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0f2f0d7-0241-4283-91e7-2007375352ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.7333   0.718 \n",
      "Null                   0.6467   0.608 \n",
      "Logistic_L1_C_1        0.732    0.716 \n",
      "Logistic_L1_C_01       0.726    0.706 \n",
      "Logistic_L1_C_10       0.7347   0.718 \n",
      "Logistic_L1_C_auto     0.7233   0.708 \n",
      "Logistic_SL1_C_auto    0.7307   0.714 \n",
      "RandomForest_noCV      0.9993   0.684 \n",
      "RandomForest_CV        0.9993   0.7   \n",
      "RandomForest_CV2       0.796    0.716 \n"
     ]
    }
   ],
   "source": [
    "#results \n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc64f0-bb1e-4934-974a-3749373b75ef",
   "metadata": {},
   "source": [
    "--->Logistic_L1_C_10 has the highest overall performance, taking into account both train and test accuracies. It obtained the greatest test accuracy (0.7347), indicating good generalization. RandomForest_noCV got the best train accuracy (0.9993), but its test accuracy (0.684) suggests overfitting. Logistic_L1_C_1 achieves an excellent balance of performance on both training and testing sets. Thus, Logistic_L1_C_1 is the optimal model for generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f57f4c-0543-4a26-b81d-c989be74c19e",
   "metadata": {},
   "source": [
    "2.Next, fit a series of logistic regression models, without regularization. Each model should use the same set of predictors (all of the relevant predictors in the dataset) and should use the entire dataset, rather than a fraction of it. Use a randomly chosen 80% proportion of observations for training and the remaining for checking the generalizable performance (i.e., performance on the holdout subset). Be sure to ensure that the training and holdout subsets are identical across all models. Each model should choose a different solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c145479d-31b1-4dac-8f13-92ad6e9011f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = df_patient.copy()\n",
    "pat_df[\"Gender\"] = pat_df[\"Gender\"].map({'male': 0, 'female': 1})\n",
    "pat_df[\"Race\"] = pat_df[\"Race\"].map({'white':0, 'hispanic':1, 'black':2, 'other':3})\n",
    "\n",
    "#Patient df\n",
    "X = pat_df[list(vars_left)]\n",
    "y= pat_df['mortality']\n",
    "\n",
    "# train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), random_state=20, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40594eac-68fb-4c2c-972e-404752dca08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89e45eb7-46be-4fbc-b2bd-6bfada02e073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 25)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5164c22f-7815-404e-abac-47c606ad69a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1174fc1-f27e-42de-a252-a67620e93e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0822c0f4-e6eb-41de-9194-f55b29b82be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#  storing  results\n",
    "result_scores = {}\n",
    "\n",
    "# logistic regression model with a specific solver\n",
    "def create_linear_model(solver_name):\n",
    "    model = LogisticRegression(\n",
    "        fit_intercept=True,\n",
    "        penalty=None,\n",
    "        solver=solver_name,\n",
    "        max_iter=10000\n",
    "    )\n",
    "\n",
    "    start_tim = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_tim = time.time()\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    elapsed_time = end_tim - start_tim\n",
    "\n",
    "    result_scores[solver_name] = (train_accuracy, test_accuracy, elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62135da7-0f7b-43e5-9e7c-ff85ce612034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solver               Training Subset Accuracy  Test Subset Accuracy      Time (s)  \n",
      "------------------------------------------------------------------------------------\n",
      "lbfgs                0.7486                    0.7348                    0.2699    \n",
      "newton-cg            0.7487                    0.7355                    0.1404    \n",
      "newton-cholesky      0.7487                    0.7355                    0.0668    \n",
      "sag                  0.7488                    0.7358                    1.2940    \n",
      "saga                 0.7488                    0.7358                    2.1957    \n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "def print_results():\n",
    "    header = f\"\\n{'Solver':20} {'Training Subset Accuracy':25} {'Test Subset Accuracy':25} {'Time (s)':10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for solver, (train_acc, test_acc, duration) in result_scores.items():\n",
    "        print(f\"{solver:20} {train_acc:<25.4f} {test_acc:<25.4f} {duration:<10.4f}\")\n",
    "\n",
    "# different solvers\n",
    "solvers = [\"lbfgs\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
    "for solver in solvers:\n",
    "    create_linear_model(solver)\n",
    "\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c1d5f4-dc61-466f-92bb-0123af81706c",
   "metadata": {},
   "source": [
    "3.Compare the results of the models in terms of their accuracy (use this as the performance metric to assess generalizability error on the holdout subset) and the time taken (use appropriate timing function). Summarize your results via a table with the following structure:\n",
    "\n",
    "Solver used                    Training subset accuracy               Holdout subset accuracy                         Time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89e99b54-203f-44d8-83d5-1d6f67709a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solver               Training Subset Accuracy  Test Subset Accuracy      Time (s)  \n",
      "------------------------------------------------------------------------------------\n",
      "lbfgs                0.7486                    0.7348                    0.2699    \n",
      "newton-cg            0.7487                    0.7355                    0.1404    \n",
      "newton-cholesky      0.7487                    0.7355                    0.0668    \n",
      "sag                  0.7488                    0.7358                    1.2940    \n",
      "saga                 0.7488                    0.7358                    2.1957    \n"
     ]
    }
   ],
   "source": [
    "#results based on accuracy.\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bedc3-c71a-4485-8165-f47bc93cf969",
   "metadata": {},
   "source": [
    "Accuracy: All solutions perform similarly, with training accuracies of approximately 0.748 and holdout accuracies ranging from 0.7348 to 0.7358. The differences are minimal, implying that all solvers generalize similarly on the holdout subgroup.\r\n",
    "\r\n",
    "Time taken: The Newton-Cholesky solver takes the shortest time (0.0668s), while the Saga solver takes the longest (2.1957s), which is much slower.\r\n",
    "\r\n",
    "The Newton-Cholesky solver strikes a reasonable balance between high accuracy and fast execution time, whereas Saga takes the longest time without considerably enhancing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68d85c-6991-43da-b58a-5d0f28e134b7",
   "metadata": {},
   "source": [
    "4.Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6afb5b-6074-4160-99de-f34fef1258b2",
   "metadata": {},
   "source": [
    "Newton-Cholesky is the best solver since it has the highest holdout subset accuracy (0.7355) and the fastest execution time (0.0668s). It strikes the ideal balance between precision and efficiency.\n",
    "\n",
    "Runner-up: Newton-cg had the same holdout subset accuracy (0.7355) as Newton-cholesky, although it took slightly longer (0.1404s) to execute. As a result, while it achieved the same level of accuracy, it was significantly less efficient.\n",
    "\n",
    "Other Solvers: lbfgs, sag, and saga achieved comparable holdout accuracies, although their execution times differed. Saga had the slowest execution time (2.1957s) with only a minor improvement in accuracy, hence it is ranked last.\n",
    "\n",
    "CONCLUSION:-\n",
    "The ranking relied primarily on holdout subset accuracy, but execution time was also an important factor in the final selection. Newton-Cholesky provided the finest mix of high accuracy and low execution time, making it the clear option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
